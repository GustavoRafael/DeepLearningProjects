{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rainDetector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoRafael/DeepLearningProjects/blob/main/rainDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmqbvsodYg9f"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "# adjust image size\n",
        "from PIL import Image\n",
        "from keras.models import model_from_json\n",
        "# data source \n",
        "#https://www.kaggle.com/somesh24/multiclass-images-for-weather-classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz9G6ppTkIWB",
        "outputId": "d08e8a44-a2fa-411a-c27a-b51a86b54485"
      },
      "source": [
        "# Path to folders with training data\n",
        "rain_path = Path(\"/rain\")\n",
        "training_data_path = Path(\"/content/training_data\")\n",
        "\n",
        "image_count = len(list(not_rain_path.glob('*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v61qYwL5uQBA"
      },
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "file_name = ''\n",
        "\n",
        "# Load all the not_rain images\n",
        "for img in training_data_path.glob(\"*.jpg\"):\n",
        "    file_name = img.stem[:4]\n",
        "    \n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img, target_size=(64, 64))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'not dog' image, the expected value should be 0\n",
        "    if file_name.lower() == 'rain':\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-aHfoy-iV0C",
        "outputId": "1e488a65-d4d4-424a-f6da-f69a8f975c01"
      },
      "source": [
        "print(len(labels))\n",
        "print(labels.count(0), labels.count(1))\n",
        "print(len(images[0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186\n",
            "100 86\n",
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz6uwCyih6km"
      },
      "source": [
        "# Create a single numpy array with all the images we loaded\n",
        "x_train = np.array(images)\n",
        "\n",
        "# Also convert the labels to a numpy array\n",
        "y_train = np.array(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhU1Nhbsny-y",
        "outputId": "4d1455b9-6dab-4d97-82c2-f7f8dee74a05"
      },
      "source": [
        "\n",
        "# Normalize image data to 0-to-1 range\n",
        "x_train = vgg16.preprocess_input(x_train)\n",
        "\n",
        "# Load a pre-trained neural network to use as a feature extractor\n",
        "pretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Extract features for each image (all in one pass)\n",
        "features_x = pretrained_nn.predict(x_train)\n",
        "\n",
        "# Save the array of extracted features to a file\n",
        "joblib.dump(features_x, \"x_train.dat\")\n",
        "\n",
        "# Save the matching array of expected values to a file\n",
        "joblib.dump(y_train, \"y_train.dat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['y_train.dat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8cywxuy3LHJ"
      },
      "source": [
        "# Load data set\n",
        "x_train = joblib.load(\"x_train.dat\")\n",
        "y_train = joblib.load(\"y_train.dat\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB7sgFL13OhQ"
      },
      "source": [
        "# Create a model and add layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ066Jz93S07",
        "outputId": "5f678966-a993-4bce-c7c4-27a4e4a54997"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 7ms/step - loss: 4.6682 - accuracy: 0.6268\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9724\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2669 - accuracy: 0.9772\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.9775\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.9883\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9950\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4098e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9750\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9877\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4303e-07 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff10ea6e350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mseaoRz3Z2r"
      },
      "source": [
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"model_weights.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRbKAHh45sYv"
      },
      "source": [
        "# Load the json file that contains the model's structure\n",
        "f = Path(\"model_structure.json\")\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recreate the Keras model object from the json data\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights\n",
        "model.load_weights(\"model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "809bGQRb8pts",
        "outputId": "d97659e6-c3f3-46ec-8972-be0b15be1e42"
      },
      "source": [
        "# evaluating testing data\n",
        "imagess =[]\n",
        "\n",
        "# Path to folders with testing data\n",
        "testing_path = Path(\"/content/test_data\")\n",
        "\n",
        "# Load all the not_rain images\n",
        "for index, img in enumerate(testing_path.glob(\"*.jpg\"), start=1):\n",
        "  \n",
        "  #image type\n",
        "  image_type = img.stem[:4]\n",
        "\n",
        "  # Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n",
        "  img = image.load_img(img, target_size=(64, 64))\n",
        "\n",
        "  # Convert the image to a numpy array\n",
        "  image_array = image.img_to_array(img)\n",
        "\n",
        "  # Add a forth dimension to the image (since Keras expects a bunch of images, not a single image)\n",
        "  images = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "  # Add the image to the list of images\n",
        "  #imagess.append(image_array )\n",
        "\n",
        "  # Normalize the data\n",
        "  images = vgg16.preprocess_input(np.array(images))\n",
        "\n",
        "  # Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n",
        "  feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "  features = feature_extraction_model.predict(images)\n",
        "\n",
        "  # Given the extracted features, make a final prediction using our own model\n",
        "  results = model.predict(features)\n",
        "  #for ind in range(len(imagess)):\n",
        "  # Since we are only testing one image with possible class, we only need to check the first result's first element\n",
        "  single_result = results[0][0]\n",
        "  \n",
        "  # Print the result\n",
        "  print(\"Image of {}: Likelihood that this image contains rain: {}%\".format(image_type.lower(), int(single_result * 100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image of rain: Likelihood that this image contains rain: 100%\n",
            "Image of rain: Likelihood that this image contains rain: 100%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n",
            "Image of clou: Likelihood that this image contains rain: 0%\n",
            "Image of rain: Likelihood that this image contains rain: 100%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n",
            "Image of rain: Likelihood that this image contains rain: 100%\n",
            "Image of clou: Likelihood that this image contains rain: 0%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n",
            "Image of rain: Likelihood that this image contains rain: 100%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n",
            "Image of clou: Likelihood that this image contains rain: 0%\n",
            "Image of rain: Likelihood that this image contains rain: 100%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n",
            "Image of sunn: Likelihood that this image contains rain: 0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}